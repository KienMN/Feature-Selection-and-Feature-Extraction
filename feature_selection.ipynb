{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:10000, :, :].reshape(10000, 28 * 28)\n",
    "y_train = y_train[:10000]\n",
    "X_test = X_test[:5000, :, :].reshape(5000, 28 * 28)\n",
    "y_test = y_test[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000,)\n",
      "(5000, 784)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple classifier model using Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.5%\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.score(X_test, y_test)\n",
    "print('Accuracy: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_columns = np.where((X_train != 0).any(axis = 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(673,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_zero_columns = X_train[:, non_zero_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the relevance between features and target\n",
    "relevance = np.corrcoef(np.append(X_train_no_zero_columns, y_train.reshape(-1, 1), axis=1).T)[-1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for k in range (250, 401, 5):\n",
    "    selected_features = np.argpartition(-relevance, k-1)[:k]\n",
    "    classifier.fit(X_train_no_zero_columns[:, selected_features], y_train)\n",
    "    acc.append((k, classifier.score(X_test[:, non_zero_columns][:, selected_features], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(250, 0.4334),\n",
       " (255, 0.4412),\n",
       " (260, 0.4462),\n",
       " (265, 0.4532),\n",
       " (270, 0.4608),\n",
       " (275, 0.477),\n",
       " (280, 0.4852),\n",
       " (285, 0.4808),\n",
       " (290, 0.4916),\n",
       " (295, 0.4916),\n",
       " (300, 0.4948),\n",
       " (305, 0.4958),\n",
       " (310, 0.5016),\n",
       " (315, 0.506),\n",
       " (320, 0.5118),\n",
       " (325, 0.5108),\n",
       " (330, 0.5086),\n",
       " (335, 0.5122),\n",
       " (340, 0.5014),\n",
       " (345, 0.502),\n",
       " (350, 0.4962),\n",
       " (355, 0.4864),\n",
       " (360, 0.4846),\n",
       " (365, 0.4682),\n",
       " (370, 0.4706),\n",
       " (375, 0.4678),\n",
       " (380, 0.4652),\n",
       " (385, 0.462),\n",
       " (390, 0.461),\n",
       " (395, 0.4602),\n",
       " (400, 0.4616)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "ax.bar([a[0] for a in acc], [a[1] for a in acc])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top relevant features\n",
    "k = 335\n",
    "selected_features = np.argpartition(-relevance, k-1)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_no_zero_columns[:, selected_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.22%\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.score(X_test[:, non_zero_columns][:, selected_features], y_test)\n",
    "print('Accuracy: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mi = mutual_info_classif(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 400\n",
    "selected_features_mi = np.argpartition(-mi, k - 1)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train[:, selected_features_mi], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.42%\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.score(X_test[:, selected_features_mi], y_test)\n",
    "print('Accuracy: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "skb = SelectKBest(score_func=mutual_info_classif, k=400)\n",
    "X_train_mi = skb.fit_transform(X_train, y_train)\n",
    "X_test_mi = skb.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_mi, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.34%\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.score(X_test_mi, y_test)\n",
    "print('Accuracy: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "skb = SelectKBest(score_func=chi2, k=400)\n",
    "X_train_chi2 = skb.fit_transform(X_train, y_train)\n",
    "X_test_chi2 = skb.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 400)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_chi2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_chi2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.46%\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.score(X_test_chi2, y_test)\n",
    "print('Accuracy: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Correlation-based Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fcbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbest = fcbf.fcbf(X_train, y_train, threshold=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.53599188e-01, 5.67000000e+02],\n",
       "       [1.52055928e-01, 3.78000000e+02],\n",
       "       [1.15814052e-01, 1.00000000e+02],\n",
       "       [1.03288468e-01, 7.12000000e+02],\n",
       "       [6.10964145e-02, 7.17000000e+02],\n",
       "       [2.10051203e-02, 7.35000000e+02],\n",
       "       [3.41024943e-03, 7.23000000e+02],\n",
       "       [1.24563366e-03, 1.95000000e+02],\n",
       "       [3.91490904e-04, 7.03000000e+02],\n",
       "       [2.12959092e-04, 3.07000000e+02],\n",
       "       [2.05158310e-04, 3.35000000e+02],\n",
       "       [2.01904041e-04, 4.47000000e+02],\n",
       "       [2.01904041e-04, 3.93000000e+02],\n",
       "       [2.00933508e-04, 6.70000000e+02],\n",
       "       [1.98938573e-04, 5.10000000e+01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected features: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of selected features: {}\".format(sbest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train[:, sbest[:, 1].astype(np.int)], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.12%\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.score(X_test[:, sbest[:, 1].astype(np.int)], y_test)\n",
    "print('Accuracy: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "sfs = SequentialFeatureSelector(estimator=GaussianNB(), k_features=200, forward=True, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sfs = sfs.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_sfs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8114"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(sfs.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particles Swarm Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyswarms as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_per_particle(mask, classifier):\n",
    "    \"\"\" Computes for the objective function per particle\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will be used to mask features\n",
    "        \n",
    "    alpha : float, default: 0.5\n",
    "        Constant weight for trading-off classifier performance and number of features\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed objective function    \n",
    "    \"\"\"\n",
    "    \n",
    "    total_features = X_train.shape[1]\n",
    "    # Get the subset of the features from the binary mask\n",
    "    m = mask.copy()\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        m = np.ones(mask.shape, dtype=np.int)\n",
    "    classifier.fit(X_train[:, m==1], y_train)\n",
    "    \n",
    "    # Compute for the objective function\n",
    "    objective_value = 1 - classifier.score(X_test[:, m==1], y_test)\n",
    "    return objective_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Higher-level method to do classification in the whole swarm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy.ndarray, shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray, shape (n_particles,)\n",
    "        The computed loss for each particle\n",
    "    \n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i], classifier=GaussianNB()) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-14 15:46:18,080 - pyswarms.discrete.binary - INFO - Optimize for 10 iters with {'c1': 2, 'c2': 2, 'w': 0.3, 'k': 20, 'p': 2}\n",
      "\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:   0%|          |0/10\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:   0%|          |0/10, best_cost=0.42\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  10%|█         |1/10, best_cost=0.42\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  10%|█         |1/10, best_cost=0.42\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  20%|██        |2/10, best_cost=0.42\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  20%|██        |2/10, best_cost=0.42\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  30%|███       |3/10, best_cost=0.42\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  30%|███       |3/10, best_cost=0.42\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  40%|████      |4/10, best_cost=0.42\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  40%|████      |4/10, best_cost=0.419\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  50%|█████     |5/10, best_cost=0.419\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  50%|█████     |5/10, best_cost=0.418\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  60%|██████    |6/10, best_cost=0.418\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  60%|██████    |6/10, best_cost=0.418\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  70%|███████   |7/10, best_cost=0.418\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  70%|███████   |7/10, best_cost=0.418\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  80%|████████  |8/10, best_cost=0.418\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  80%|████████  |8/10, best_cost=0.418\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  90%|█████████ |9/10, best_cost=0.418\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary:  90%|█████████ |9/10, best_cost=0.418\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pyswarms.discrete.binary: 100%|██████████|10/10, best_cost=0.418\u001b[A\u001b[A\u001b[A\n",
      "2019-10-14 15:46:38,177 - pyswarms.discrete.binary - INFO - Optimization finished | best cost: 0.41800000000000004, best pos: [1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1\n",
      " 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1\n",
      " 0 1 0 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1\n",
      " 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0\n",
      " 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0\n",
      " 0 0 1 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1\n",
      " 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 0 1 0 0 1\n",
      " 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 1 0 1 0 0\n",
      " 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0\n",
      " 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1\n",
      " 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0\n",
      " 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0\n",
      " 0 1 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "options = {'c1': 2, 'c2': 2, 'w': 0.3, 'k': 20, 'p': 2}\n",
    "pso = ps.discrete.BinaryPSO(n_particles=20, dimensions=X_train.shape[1], options=options)\n",
    "cost, pos = pso.optimize(f, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41800000000000004"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train[:, pos==1], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.582"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = classifier.score(X_test[:, pos==1], y_test)\n",
    "print('Accuracy: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 375\n"
     ]
    }
   ],
   "source": [
    "print('Number of features: {}'.format(np.count_nonzero(pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithms (GA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When applying GA to a given problem, we have to determine the representation of the gene, the suitable fitness function, and how the crossover and the mutation are applied. Let’s see how things work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genetic_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Genetic algorithm parameters:\n",
    "    Population size\n",
    "    Mating pool size\n",
    "    Number of mutations\n",
    "\"\"\"\n",
    "sol_per_pop = 30 # Population size.\n",
    "num_parents_mating = 20 # Number of parents inside the mating pool.\n",
    "num_mutations = 20 # Number of elements to mutate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the population shape\n",
    "pop_shape = (sol_per_pop, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 784)\n"
     ]
    }
   ],
   "source": [
    "# Creating the initial population.\n",
    "new_population = np.random.randint(low=0, high=2, size=pop_shape)\n",
    "print(new_population.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_outputs = []\n",
    "num_generations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 0\n",
      "Best result: 0.5508\n",
      "Generation: 1\n",
      "Best result: 0.5562\n",
      "Generation: 2\n",
      "Best result: 0.5848\n",
      "Generation: 3\n",
      "Best result: 0.5848\n",
      "Generation: 4\n",
      "Best result: 0.5848\n",
      "Generation: 5\n",
      "Best result: 0.5848\n",
      "Generation: 6\n",
      "Best result: 0.5848\n",
      "Generation: 7\n",
      "Best result: 0.5848\n",
      "Generation: 8\n",
      "Best result: 0.5848\n",
      "Generation: 9\n",
      "Best result: 0.5848\n",
      "Generation: 10\n",
      "Best result: 0.5848\n",
      "Generation: 11\n",
      "Best result: 0.5848\n",
      "Generation: 12\n",
      "Best result: 0.603\n",
      "Generation: 13\n",
      "Best result: 0.603\n",
      "Generation: 14\n",
      "Best result: 0.604\n",
      "Generation: 15\n",
      "Best result: 0.6116\n",
      "Generation: 16\n",
      "Best result: 0.6116\n",
      "Generation: 17\n",
      "Best result: 0.6116\n",
      "Generation: 18\n",
      "Best result: 0.6116\n",
      "Generation: 19\n",
      "Best result: 0.613\n",
      "Generation: 20\n",
      "Best result: 0.6152\n",
      "Generation: 21\n",
      "Best result: 0.629\n",
      "Generation: 22\n",
      "Best result: 0.629\n",
      "Generation: 23\n",
      "Best result: 0.629\n",
      "Generation: 24\n",
      "Best result: 0.629\n",
      "Generation: 25\n",
      "Best result: 0.629\n",
      "Generation: 26\n",
      "Best result: 0.629\n",
      "Generation: 27\n",
      "Best result: 0.629\n",
      "Generation: 28\n",
      "Best result: 0.629\n",
      "Generation: 29\n",
      "Best result: 0.629\n",
      "Generation: 30\n",
      "Best result: 0.629\n",
      "Generation: 31\n",
      "Best result: 0.6292\n",
      "Generation: 32\n",
      "Best result: 0.6292\n",
      "Generation: 33\n",
      "Best result: 0.6292\n",
      "Generation: 34\n",
      "Best result: 0.633\n",
      "Generation: 35\n",
      "Best result: 0.633\n",
      "Generation: 36\n",
      "Best result: 0.633\n",
      "Generation: 37\n",
      "Best result: 0.633\n",
      "Generation: 38\n",
      "Best result: 0.633\n",
      "Generation: 39\n",
      "Best result: 0.633\n",
      "Generation: 40\n",
      "Best result: 0.646\n",
      "Generation: 41\n",
      "Best result: 0.646\n",
      "Generation: 42\n",
      "Best result: 0.646\n",
      "Generation: 43\n",
      "Best result: 0.646\n",
      "Generation: 44\n",
      "Best result: 0.6466\n",
      "Generation: 45\n",
      "Best result: 0.6466\n",
      "Generation: 46\n",
      "Best result: 0.6466\n",
      "Generation: 47\n",
      "Best result: 0.6606\n",
      "Generation: 48\n",
      "Best result: 0.6606\n",
      "Generation: 49\n",
      "Best result: 0.6606\n"
     ]
    }
   ],
   "source": [
    "for generation in range(num_generations):\n",
    "    print('Generation: {}'.format(generation))\n",
    "    # Measuring the fitness of each chromosome in the population.\n",
    "    fitness = genetic_algorithm.cal_pop_fitness(new_population, X_train, y_train, X_test, y_test)\n",
    "    # The best result in the current generation\n",
    "    best_outputs.append(np.max(fitness))\n",
    "    print('Best result: {}'.format(best_outputs[-1]))\n",
    "    \n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents = genetic_algorithm.select_mating_pool(new_population, fitness, num_parents_mating)\n",
    "    \n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossover = genetic_algorithm.crossover(parents, offspring_size=(pop_shape[0] - parents.shape[0], X_train.shape[1]))\n",
    "    \n",
    "    # Adding some variations to the offspring using mutation.\n",
    "    offspring_mutation = genetic_algorithm.mutation(offspring_crossover, num_mutations=num_generations)\n",
    "    \n",
    "    # Creating the new population based on the parents and offspring.\n",
    "    new_population[0: parents.shape[0], :] = parents.copy()\n",
    "    new_population[parents.shape[0]:, :] = offspring_mutation.copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best solution after iterating finishing all generations.\n",
    "# At first, the fitness is calculated for each solution in the final generation.\n",
    "fitness = genetic_algorithm.cal_pop_fitness(new_population, X_train, y_train, X_test, y_test)\n",
    "# Then return the index of that solution corresponding to the best fitness.\n",
    "best_match_idx = np.where(fitness == np.max(fitness))[0]\n",
    "best_match_idx = best_match_idx[0]\n",
    "\n",
    "best_solution = new_population[best_match_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train[:, best_solution == 1], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6606"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = classifier.score(X_test[:, best_solution == 1], y_test)\n",
    "print('Accuracy: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 372\n"
     ]
    }
   ],
   "source": [
    "print('Number of features: {}'.format(np.count_nonzero(best_solution)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
